import streamlit as st
from audio_recorder_streamlit import audio_recorder
import torch
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import librosa
import numpy as np
import math
from jiwer import wer
import google.generativeai as genai
import os
import io
import soundfile as sf

# Gemini APIã‚­ãƒ¼
try:
    GOOGLE_API_KEY = os.environ["GOOGLE_API_KEY"]
except KeyError:
    st.error("ç’°å¢ƒå¤‰æ•° GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

MODEL_CHECKPOINT = "openai/whisper-base.en"
WHISPER_MAX_LENGTH = 448
SIGMOID_A = 0.5
SIGMOID_B = 6
DEFAULT_SAMPLE_RATE = 16000

_model_scorer = None
_processor_scorer = None
_device_scorer = None

def _initialize_scoring_model_and_processor():
    global _model_scorer, _processor_scorer, _device_scorer
    if _model_scorer is None or _processor_scorer is None:
        _device_scorer = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        try:
            _processor_scorer = WhisperProcessor.from_pretrained(MODEL_CHECKPOINT)
            _model_scorer = WhisperForConditionalGeneration.from_pretrained(MODEL_CHECKPOINT).to(_device_scorer)
            _model_scorer.eval()
            return True
        except Exception as e:
            st.error(f"Whisperãƒ¢ãƒ‡ãƒ«/ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return False
    return True

def preprocess_audio_for_scoring(audio_path_or_data, sampling_rate_in=None):
    if not _initialize_scoring_model_and_processor():
        raise Exception("Scoring model could not be initialized.")
    target_sr = DEFAULT_SAMPLE_RATE
    if isinstance(audio_path_or_data, str):
        try:
            audio, sr_orig = librosa.load(audio_path_or_data, sr=None, mono=True)
        except Exception as e:
            st.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« {audio_path_or_data} ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    elif isinstance(audio_path_or_data, np.ndarray):
        if sampling_rate_in is None:
            raise ValueError("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒnumpyé…åˆ—ã®å ´åˆã€sampling_rate_inã®æŒ‡å®šãŒå¿…è¦ã§ã™ã€‚")
        audio = audio_path_or_data
        sr_orig = sampling_rate_in
        if audio.ndim > 1 and audio.shape[1] > 1:
             audio = np.mean(audio, axis=1)
        elif audio.ndim > 1 and audio.shape[1] == 1:
            audio = audio.squeeze()
        elif audio.ndim == 1:
            pass
        else:
            st.error(f"äºˆæœŸã—ãªã„Numpyé…åˆ—ã®å½¢çŠ¶ã§ã™: {audio.shape}")
            raise ValueError(f"äºˆæœŸã—ãªã„Numpyé…åˆ—ã®å½¢çŠ¶: {audio.shape}")
    else:
        raise ValueError("audio_path_or_data ã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹(str)ã¾ãŸã¯numpyé…åˆ—ã¨sampling_rate_inã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
    if sr_orig != target_sr:
        try:
            audio = librosa.resample(audio, orig_sr=sr_orig, target_sr=target_sr)
        except Exception as e:
            st.error(f"éŸ³å£°ã®ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    try:
        input_features = _processor_scorer(audio, sampling_rate=target_sr, return_tensors="pt").input_features
        return input_features.to(_device_scorer)
    except Exception as e:
        st.error(f"Whisperãƒ—ãƒ­ã‚»ãƒƒã‚µã§ã®éŸ³å£°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        raise

def calculate_entropy(probabilities):
    probabilities = torch.where(probabilities == 0, torch.tensor(1e-12, device=probabilities.device), probabilities)
    return -torch.sum(probabilities * torch.log(probabilities), dim=-1)

def calculate_wer(reference, hypothesis):
    return wer(reference, hypothesis)

def calculate_fluency_score(perplexity, a=SIGMOID_A, b=SIGMOID_B):
    if math.isnan(perplexity) or math.isinf(perplexity):
        return 0.0
    return 100 / (1 + math.exp(a * (perplexity - b)))

def evaluate_speech(audio_path_or_data, ground_truth_text, sampling_rate_in=None):
    if not _initialize_scoring_model_and_processor():
        return {"total_entropy": float('nan'), "total_perplexity": float('nan'),"total_fluency_score": 0.0, "decoded_text": "ã‚¨ãƒ©ãƒ¼: è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚","wer": 1.0, "words_with_metrics": []}
    try:
        input_features = preprocess_audio_for_scoring(audio_path_or_data, sampling_rate_in)
    except Exception as e:
        return {"total_entropy": float('nan'), "total_perplexity": float('nan'),"total_fluency_score": 0.0, "decoded_text": "ã‚¨ãƒ©ãƒ¼: éŸ³å£°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚","wer": 1.0, "words_with_metrics": []}
    with torch.no_grad():
        try:
            outputs = _model_scorer.generate(input_features=input_features,return_dict_in_generate=True,output_scores=True,max_length=WHISPER_MAX_LENGTH,num_beams=1,do_sample=False)
        except Exception as e:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ç”Ÿæˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return {"total_entropy": float('nan'), "total_perplexity": float('nan'),"total_fluency_score": 0.0, "decoded_text": "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚","wer": 1.0, "words_with_metrics": []}
        predicted_ids_full = outputs.sequences
        stacked_scores = torch.stack(outputs.scores, dim=1)
        probabilities = torch.softmax(stacked_scores, dim=-1)
    squeezed_probabilities = probabilities.squeeze(0)
    if squeezed_probabilities.ndim == 1 and squeezed_probabilities.shape[0] == _model_scorer.config.vocab_size:
        squeezed_probabilities = squeezed_probabilities.unsqueeze(0)
    if squeezed_probabilities.numel() == 0 or squeezed_probabilities.ndim < 2:
        token_entropies = torch.tensor([], device=_device_scorer)
    else:
        token_entropies = calculate_entropy(squeezed_probabilities)
    token_perplexities = torch.exp(token_entropies) if token_entropies.numel() > 0 else torch.tensor([], device=_device_scorer)
    decoded_preds_list = _processor_scorer.batch_decode(predicted_ids_full, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    decoded_preds = decoded_preds_list[0].strip() if decoded_preds_list else ""
    token_ids = predicted_ids_full[0].tolist()
    words_with_metrics = []
    for i_token_loop in range(len(token_perplexities)):
        if i_token_loop + 1 < len(token_ids):
            current_token_id_in_sequence = token_ids[i_token_loop+1]
            word = _processor_scorer.decode([current_token_id_in_sequence], skip_special_tokens=True, clean_up_tokenization_spaces=True)
            if word.strip():
                word_perplexity_val = token_perplexities[i_token_loop].item()
                word_fluency_score_val = calculate_fluency_score(word_perplexity_val)
                words_with_metrics.append({"word": word.strip(),"entropy": token_entropies[i_token_loop].item(),"perplexity": word_perplexity_val,"fluency_score": word_fluency_score_val})
    if len(token_entropies) > 0:
        total_entropy_val = token_entropies.mean().item()
        total_perplexity_val = torch.exp(torch.tensor(total_entropy_val, device=_device_scorer)).item()
        total_fluency_score_val = calculate_fluency_score(total_perplexity_val)
    else:
        total_entropy_val = float('nan')
        total_perplexity_val = float('nan')
        total_fluency_score_val = 0.0
    wer_val = calculate_wer(ground_truth_text.lower().strip(), decoded_preds.lower().strip())
    return {"total_entropy": total_entropy_val,"total_perplexity": total_perplexity_val,"total_fluency_score": total_fluency_score_val,"decoded_text": decoded_preds,"wer": wer_val,"words_with_metrics": words_with_metrics}


# Gemini API
genai.configure(api_key=GOOGLE_API_KEY)
gemini_model_feedback = genai.GenerativeModel('gemini-2.0-flash-lite')

def generate_sentence_for_pronunciation_practice(topic="æ—¥å¸¸ä¼šè©±", difficulty="åˆç´šã‹ã‚‰ä¸­ç´š", word_count=(7, 15)):
    prompt = f"""æ—¥æœ¬äººè‹±èªå­¦ç¿’è€…ã®ãŸã‚ã®ã€ç™ºéŸ³ç·´ç¿’ã«é©ã—ãŸè‡ªç„¶ãªè‹±èªã®æ–‡ç« ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚æ–‡ç« ã¯ä»¥ä¸‹ã®æ¡ä»¶ã‚’æº€ãŸã™ã‚ˆã†ã«ã—ã¦ãã ã•ã„ï¼š- ãƒˆãƒ”ãƒƒã‚¯: ã€Œ{topic}ã€ã«é–¢é€£ã™ã‚‹ã‚‚ã® - é›£æ˜“åº¦: {difficulty}ãƒ¬ãƒ™ãƒ«ã®å­¦ç¿’è€…å‘ã‘ - å˜èªæ•°: {word_count[0]}èªã‹ã‚‰{word_count[1]}èªç¨‹åº¦ - ä¸€èˆ¬çš„ã§å¹³æ˜“ãªèªå½™ã‚’ä½¿ç”¨ã—ã€è¤‡é›‘ã™ãã‚‹æ–‡æ³•ã‚„ç‰¹æ®Šãªã‚¹ãƒ©ãƒ³ã‚°ã¯é¿ã‘ã‚‹ - å®Œå…¨ãªä¸€ã¤ã®æ–‡ç« ã§ã‚ã‚‹ã“ã¨ ç”Ÿæˆã™ã‚‹ã®ã¯è‹±èªã®æ–‡ç« ã®ã¿ã¨ã—ã€ã€ŒHere is a sentence:ã€ã®ã‚ˆã†ãªå‰ç½®ãã¯ä¸è¦ã§ã™ã€‚ä¾‹: I enjoy listening to music in my free time."""
    try:
        response = gemini_model_feedback.generate_content(prompt)
        sentence = response.text.strip()
        if sentence.startswith('"') and sentence.endswith('"'):
            sentence = sentence[1:-1]
        if not sentence: return "I would like to try that new cafe."
        return sentence
    except Exception as e:
        st.warning(f"Geminiã«ã‚ˆã‚‹æ•™å¸«æ–‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return "The park is a beautiful place to relax."

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
def generate_simplified_feedback(teacher_sentence, whisper_results):
    prompt = f"""
    ã‚ãªãŸã¯è‹±èªå­¦ç¿’è€…ã®ç™ºéŸ³ã‚’è©•ä¾¡ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€å­¦ç¿’è€…ã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’**å³å¯†ã«æŒ‡å®šã•ã‚ŒãŸå½¢å¼ã§**æ—¥æœ¬èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

    ## å…¥åŠ›æƒ…å ±
    ãŠæ‰‹æœ¬: "{teacher_sentence}"
    å­¦ç¿’è€…ã®ç™ºéŸ³ (AIèªè­˜): "{whisper_results['decoded_text']}"
    å˜èªèª¤ã‚Šç‡ (WER): {whisper_results['wer']:.2%} (0%ã«è¿‘ã„ã»ã©è‰¯ã„)
    ç·åˆæµæš¢ã•ã‚¹ã‚³ã‚¢ (AIã«ã‚ˆã‚‹æ¨å®š): {whisper_results['total_fluency_score']:.0f}/100 (100ã«è¿‘ã„ã»ã©è‰¯ã„)

    ## å‡ºåŠ›å½¢å¼ (ã“ã®å½¢å¼ã‚’å³å®ˆã—ã¦ãã ã•ã„)
    ç·åˆã‚¹ã‚³ã‚¢: [0-100ã®æ•´æ•°å€¤]/100 ç‚¹

    ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¹:
    [ã“ã“ã«1ã€œ2ç‚¹ã®ç°¡æ½”ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹]

    ## æŒ‡ç¤º
    - ç·åˆã‚¹ã‚³ã‚¢ã¯ã€å˜èªèª¤ã‚Šç‡ã¨æµæš¢ã•ã‚¹ã‚³ã‚¢ã‚’ç·åˆçš„ã«åˆ¤æ–­ã—ã¦ã€0ã‹ã‚‰100ã®æ•´æ•°ã§æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚
    - ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¯ã€å­¦ç¿’è€…ãŒã‚„ã‚‹æ°—ã‚’æãªã‚ãªã„ã‚ˆã†ã«è‰¯ã„ã¨ã“ã‚ã‚’èª‰ã‚ã¤ã¤ã€æ¬¡ã«ä½•ã‚’æ„è­˜ã™ã‚Œã°è‰¯ã„ã‹ã€æ˜ç¢ºãªè¡Œå‹•æŒ‡é‡ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
    - ä½™è¨ˆãªæŒ¨æ‹¶ã‚„å‰ç½®ãã€ä¾‹ç¤ºã®ç¹°ã‚Šè¿”ã—ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
    """
    try:
        response = gemini_model_feedback.generate_content(prompt)
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«è¡¨ç¤ºã—ã¦ã¿ã‚‹
        # st.write("--- Gemini Raw Response ---")
        # st.text(response.text)
        # st.write("--- End Gemini Raw Response ---")
        return response.text.strip()
    except Exception as e:
        st.warning(f"Geminiã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return "ç·åˆã‚¹ã‚³ã‚¢: åˆ¤å®šä¸èƒ½/100 ç‚¹\n\nãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¹:\nãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"

# Streamlit ã‚¢ãƒ—ãƒªã®UI
st.set_page_config(page_title="è‹±èªç™ºéŸ³ç·´ç¿’ã‚¢ãƒ—ãƒª", layout="centered") # ä¸­å¤®æƒãˆã«å¤‰æ›´
st.title("AIè‹±èªç™ºéŸ³ã‚³ãƒ¼ãƒ ğŸ¤")

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰çŠ¶æ…‹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ç®¡ç†
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False

if not st.session_state.model_loaded:
    with st.spinner("AIãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ä¸­..."):
        if _initialize_scoring_model_and_processor():
            st.session_state.model_loaded = True
        else:
            st.error("ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            st.stop()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– (ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ãªã©)
if 'current_step' not in st.session_state:
    st.session_state.current_step = 1 # 1: æ–‡ç”Ÿæˆ, 2: éŒ²éŸ³, 3: çµæœè¡¨ç¤º
if 'teacher_sentence' not in st.session_state:
    st.session_state.teacher_sentence = ""
if 'feedback' not in st.session_state: # ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”¨
    st.session_state.feedback = ""
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'audio_bytes_data' not in st.session_state:
    st.session_state.audio_bytes_data = None

# ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ç”»é¢å®šç¾©

def step1_generate_sentence():
    st.header("ã‚¹ãƒ†ãƒƒãƒ—1: ç·´ç¿’ã™ã‚‹è‹±æ–‡ã‚’ç¢ºèª")
    st.write("ä¸‹ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€ç·´ç¿’ã™ã‚‹è‹±æ–‡ã‚’ç”Ÿæˆã—ã¾ã—ã‚‡ã†ã€‚")

    if st.button("æ•™å¸«æ–‡ã‚’ç”Ÿæˆã™ã‚‹", key="generate_sentence_btn", type="primary", use_container_width=True):
        with st.spinner("ç·´ç¿’æ–‡ã‚’ç”Ÿæˆä¸­..."):
            st.session_state.teacher_sentence = generate_sentence_for_pronunciation_practice(
                topic="ç°¡å˜ãªæ—¥å¸¸ä¼šè©±",
                difficulty="åˆç´š"
            )
            # ãƒªã‚»ãƒƒãƒˆå‡¦ç†
            st.session_state.feedback = ""
            st.session_state.analysis_results = None
            st.session_state.audio_bytes_data = None
            st.session_state.current_step = 2 # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸
            st.rerun() # ç”»é¢ã‚’å†æç”»ã—ã¦ã‚¹ãƒ†ãƒƒãƒ—2ã‚’è¡¨ç¤º

    if st.session_state.teacher_sentence and st.session_state.current_step != 1 : # ç”Ÿæˆæ¸ˆã¿ã ãŒã¾ã ã‚¹ãƒ†ãƒƒãƒ—1ã«ã„ã‚‹å ´åˆ(ã»ã¼ãªã„ã¯ãš)
        st.info(f"**ãŠé¡Œ:**\n\n## \"{st.session_state.teacher_sentence}\"")
        if st.button("ã“ã®ãŠé¡Œã§ç·´ç¿’é–‹å§‹ â†’", use_container_width=True):
            st.session_state.current_step = 2
            st.rerun()

def step2_record_audio():
    st.header("ã‚¹ãƒ†ãƒƒãƒ—2: ãŠæ‰‹æœ¬ã‚’ç™ºéŸ³ã—ã¦éŒ²éŸ³")
    if not st.session_state.teacher_sentence:
        st.warning("ã¾ãšã‚¹ãƒ†ãƒƒãƒ—1ã§ãŠé¡Œã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        if st.button("â† ã‚¹ãƒ†ãƒƒãƒ—1ã«æˆ»ã‚‹", use_container_width=True):
            st.session_state.current_step = 1
            st.rerun()
        return

    st.info(f"**ãŠé¡Œ:**\n\n## \"{st.session_state.teacher_sentence}\"")
    st.markdown("---")
    st.write("ä¸‹ã®ãƒã‚¤ã‚¯ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ä¸Šã®è‹±æ–‡ã‚’ç™ºéŸ³ã—ã¦ãã ã•ã„ã€‚")

    recorded_audio_bytes = audio_recorder(
        text="â–¶ï¸ ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŒ²éŸ³é–‹å§‹",
        recording_color="#e87070",
        neutral_color="#6aa36f",
        icon_size="3x", # å°‘ã—å¤§ãã
        pause_threshold=2.0, # ç„¡éŸ³åœæ­¢ã¾ã§ã®ç§’æ•° (çŸ­ã‚ã«)
        sample_rate=DEFAULT_SAMPLE_RATE
    )

    if recorded_audio_bytes:
        st.session_state.audio_bytes_data = recorded_audio_bytes
        st.audio(st.session_state.audio_bytes_data, format='audio/wav')
        st.markdown("---")
        col_nav1, col_nav2 = st.columns(2)
        with col_nav1:
            if st.button("â† éŒ²ã‚Šç›´ã™", use_container_width=True):
                st.session_state.audio_bytes_data = None # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                st.rerun()
        with col_nav2:
            if st.button("ã“ã‚Œã§è©•ä¾¡ã™ã‚‹ â†’", type="primary", use_container_width=True):
                st.session_state.current_step = 3
                st.rerun()
    
    st.markdown("---")
    if st.button("åˆ¥ã®ç·´ç¿’æ–‡ã«ã™ã‚‹ (ã‚¹ãƒ†ãƒƒãƒ—1ã¸)", use_container_width=True):
        st.session_state.current_step = 1
        st.session_state.teacher_sentence = "" # ç·´ç¿’æ–‡ã‚‚ã‚¯ãƒªã‚¢
        st.rerun()


def step3_show_results():
    st.header("ã‚¹ãƒ†ãƒƒãƒ—3: AIã‚³ãƒ¼ãƒã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
    if not st.session_state.audio_bytes_data or not st.session_state.teacher_sentence:
        st.warning("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ç·´ç¿’æ–‡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ãƒ†ãƒƒãƒ—1ã‹ã‚‰ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚")
        if st.button("ã‚¹ãƒ†ãƒƒãƒ—1ã«æˆ»ã‚‹", use_container_width=True):
            st.session_state.current_step = 1
            st.rerun()
        return

    # è©•ä¾¡å‡¦ç†ï¼ˆä¸€åº¦ã ã‘å®Ÿè¡Œã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼‰
    if st.session_state.analysis_results is None:
        with st.spinner("ã‚ãªãŸã®ç™ºéŸ³ã‚’è©•ä¾¡ä¸­ã§ã™...ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚"):
            try:
                audio_data_io = io.BytesIO(st.session_state.audio_bytes_data)
                audio_np, sr = sf.read(audio_data_io, dtype='float32')
                
                analysis = evaluate_speech(
                    audio_path_or_data=audio_np,
                    sampling_rate_in=sr,
                    ground_truth_text=st.session_state.teacher_sentence
                )
                st.session_state.analysis_results = analysis

                # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
                feedback_text = generate_simplified_feedback(
                    st.session_state.teacher_sentence,
                    analysis
                )
                st.session_state.feedback = feedback_text
                st.success("è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            except Exception as e:
                st.error(f"è©•ä¾¡å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.error("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã‚‹ã‹ã€å½¢å¼ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                if st.button("ã‚„ã‚Šç›´ã™ (ã‚¹ãƒ†ãƒƒãƒ—2ã¸)", use_container_width=True):
                    st.session_state.current_step = 2
                    st.session_state.analysis_results = None # çµæœã‚’ã‚¯ãƒªã‚¢
                    st.session_state.feedback = ""
                    st.rerun()
                return # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä»¥é™ã®è¡¨ç¤ºã‚’ã‚¹ã‚­ãƒƒãƒ—
    
    # çµæœè¡¨ç¤º
    if st.session_state.analysis_results:
        results = st.session_state.analysis_results
        st.info(f"**ç·´ç¿’ã—ãŸãŠé¡Œ:** \"{st.session_state.teacher_sentence}\"")
        
        with st.container(border=True):
            st.markdown("#### AIã«ã‚ˆã‚‹èªè­˜çµæœ")
            st.write(f"`{results['decoded_text']}`")
        
        st.markdown("---")

        if st.session_state.feedback:
            st.markdown("#### AIã‚³ãƒ¼ãƒã‹ã‚‰")
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ–‡å­—åˆ—ã‚’ "ç·åˆã‚¹ã‚³ã‚¢:" ã¨ "ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¹:" ã§åˆ†å‰²ã—ã¦è¡¨ç¤º
            feedback_parts = st.session_state.feedback.split("ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¹:")
            if len(feedback_parts) >= 1:
                score_part = feedback_parts[0].replace("ç·åˆã‚¹ã‚³ã‚¢:", "").strip()
                try:
                    # "X/100 ç‚¹" ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
                    actual_score_str = score_part.split("/")[0].strip()
                    actual_score = int(actual_score_str)
                    st.metric(label="ç·åˆã‚¹ã‚³ã‚¢", value=f"{actual_score} / 100 ç‚¹")
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§è¦–è¦šåŒ–
                    st.progress(actual_score / 100.0)
                except: # ã‚¹ã‚³ã‚¢å½¢å¼ãŒäºˆæœŸã—ãªã„å ´åˆ
                    st.markdown(f"**ç·åˆã‚¹ã‚³ã‚¢:** {score_part}")


            if len(feedback_parts) >= 2:
                advice_part = feedback_parts[1].strip()
                st.markdown("**ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¹:**")
                st.success(f"{advice_part}") # success ã‚’ä½¿ã£ã¦ç›®ç«‹ãŸã›ã‚‹
            elif len(feedback_parts) == 1 and "ç·åˆã‚¹ã‚³ã‚¢:" not in feedback_parts[0]: # ã‚¹ã‚³ã‚¢éƒ¨åˆ†ãŒãªãã‚¢ãƒ‰ãƒã‚¤ã‚¹ã®ã¿ã®å ´åˆ
                st.markdown("**ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¹:**")
                st.success(f"{feedback_parts[0].strip()}")


        # è©³ç´°ãªåˆ†æçµæœã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§è¡¨ç¤º
        with st.expander("ã‚ˆã‚Šè©³ã—ã„åˆ†æçµæœã‚’è¦‹ã‚‹ (ä¸Šç´šè€…å‘ã‘)"):
            st.markdown(f"**å˜èªèª¤ã‚Šç‡ (WER):** {results['wer']:.2%} (ä½ã„ã»ã©è‰¯ã„)")
            st.markdown(f"**AIã«ã‚ˆã‚‹ç·åˆçš„ãªæµæš¢ã•:** {results['total_fluency_score']:.0f}/100 (é«˜ã„ã»ã©è‰¯ã„)")
            if results['words_with_metrics']:
                st.markdown("**å˜èªã”ã¨ã®è©³ç´°:**")
                word_data = []
                for item in results['words_with_metrics']:
                    word_data.append({
                        "å˜èª/ãƒˆãƒ¼ã‚¯ãƒ³": item['word'],
                        "ãƒ‘ãƒ¼ãƒ—ãƒ¬ã‚­ã‚·ãƒ†ã‚£": f"{item['perplexity']:.2f}",
                        "æµæš¢ã•ã‚¹ã‚³ã‚¢": f"{item['fluency_score']:.0f}/100"
                    })
                st.dataframe(word_data, use_container_width=True, hide_index=True)
            else:
                st.write("å˜èªã”ã¨ã®è©³ç´°ãªåˆ†æãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    st.markdown("---")
    col_nav_end1, col_nav_end2 = st.columns(2)
    with col_nav_end1:
        if st.button("ã‚‚ã†ä¸€åº¦åŒã˜ãŠé¡Œã§ç·´ç¿’ (ã‚¹ãƒ†ãƒƒãƒ—2ã¸)", use_container_width=True):
            st.session_state.current_step = 2
            st.session_state.analysis_results = None # çµæœã‚’ã‚¯ãƒªã‚¢ã—ã¦å†è©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
            st.session_state.feedback = ""
            st.session_state.audio_bytes_data = None # éŒ²éŸ³ã‚‚ã‚¯ãƒªã‚¢
            st.rerun()
    with col_nav_end2:
        if st.button("æ–°ã—ã„ãŠé¡Œã§ç·´ç¿’ (ã‚¹ãƒ†ãƒƒãƒ—1ã¸)", type="primary", use_container_width=True):
            st.session_state.current_step = 1
            st.session_state.teacher_sentence = "" # å…¨ã¦ãƒªã‚»ãƒƒãƒˆ
            st.session_state.analysis_results = None
            st.session_state.feedback = ""
            st.session_state.audio_bytes_data = None
            st.rerun()


# ãƒ¡ã‚¤ãƒ³ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
if st.session_state.model_loaded: # ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚Œã°å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¡¨ç¤º
    if st.session_state.current_step == 1:
        step1_generate_sentence()
    elif st.session_state.current_step == 2:
        step2_record_audio()
    elif st.session_state.current_step == 3:
        step3_show_results()
else:
    st.info("ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã‚’ãŠå¾…ã¡ãã ã•ã„...")


st.markdown("---")
st.caption("Â© 2024 AIè‹±èªç™ºéŸ³ã‚³ãƒ¼ãƒ")